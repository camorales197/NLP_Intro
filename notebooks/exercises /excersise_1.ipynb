{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise\n",
    "\n",
    "1. Data Loading and Initial Exploration\n",
    "\n",
    "   - a. Download the 20 Newsgroups dataset using `fetch_20newsgroups` from `sklearn.datasets`.\n",
    "   - b. Load the dataset into a pandas DataFrame.\n",
    "   - c. Display the first few rows to understand the structure.\n",
    "   - d. Get a summary of the dataset:\n",
    "     - Number of samples.\n",
    "     - Distribution of classes\n",
    "     - Any missing values.\n",
    "\n",
    "2. Text Preprocessing\n",
    "\n",
    "   After looking at the data, perform the relevant preprocessing steps on the news texts:\n",
    "\n",
    "   - Noise Removal. \n",
    "   - Lexicon Normalization\n",
    "   - Object Standardization\n",
    "\n",
    "3. Exploratory Data Analysis (EDA)\n",
    "\n",
    "   - a. Word Cloud\n",
    "     - Generate separate word clouds for a few selected newsgroups to visualize the most frequent words.\n",
    "   - b. Frequency Distribution\n",
    "     - Plot the top 20 most frequent words in the entire dataset after preprocessing.\n",
    "   - c. Class Distribution\n",
    "     - Visualize the distribution of the 20 newsgroups using a bar chart.\n",
    "\n",
    "4. Feature Extraction\n",
    "\n",
    "   - a. Part-of-Speech (POS) Tagging\n",
    "     - Perform POS tagging on a random sample of 500 news articles.\n",
    "     - Analyze the frequency of different POS tags.\n",
    "   - b. Named Entity Recognition (NER)\n",
    "     - Apply NER on the same sample of news articles.\n",
    "     - Extract and list the most common entities (e.g., persons, organizations, locations).\n",
    "   - c. TF-IDF Vectorization\n",
    "     - Convert the preprocessed news articles into TF-IDF feature vectors.\n",
    "     - Examine the shape of the resulting feature matrix.\n",
    "\n",
    "5. Model Building\n",
    "\n",
    "   - a. Train-Test Split\n",
    "     - Split the dataset into training and testing sets (e.g., 80% train, 20% test).\n",
    "   - b. Classification Model\n",
    "     - Choose a classifier (e.g., Logistic Regression, Naive Bayes, Support Vector Machine).\n",
    "     - Train the model on the TF-IDF feature vectors.\n",
    "     - Predict the newsgroup categories on the test set.\n",
    "   - c. Evaluation\n",
    "     - Calculate evaluation metrics:\n",
    "       - Accuracy\n",
    "       - Precision\n",
    "       - Recall\n",
    "       - F1-score\n",
    "     - Display a confusion matrix.\n",
    "     - Interpret the results.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The way to download the dataset is as follows. Make sure that you do not use the twenty_test data set for training, as it is meant for the final evaluation. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "twenty_train = fetch_20newsgroups(\n",
    "    subset=\"train\", shuffle=True, download_if_missing=True\n",
    ")\n",
    "twenty_test = fetch_20newsgroups(subset=\"test\", shuffle=True, download_if_missing=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp-intro-uCSESLWM-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
